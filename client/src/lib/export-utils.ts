import type { AgentConfig } from "@shared/schema";
import JSZip from "jszip";

export async function generateExportPackage(agent: Partial<AgentConfig>): Promise<void> {
  const zip = new JSZip();
  const agentName = agent.name?.replace(/\s+/g, "_").toLowerCase() || "my_agent";

  // Agent config JSON
  const configJson = JSON.stringify(
    {
      name: agent.name || "AI Assistant",
      goal: agent.goal || "",
      personality: agent.personality || "",
      tools: agent.tools || [],
      model: agent.modelId || "gpt-4o",
      temperature: agent.temperature || 0.7,
      maxTokens: agent.maxTokens || 4096,
    },
    null,
    2
  );
  zip.file(`${agentName}/config.json`, configJson);

  // Python agent script
  const pythonScript = generatePythonScript(agent);
  zip.file(`${agentName}/agent.py`, pythonScript);

  // Requirements file
  const requirements = `langchain>=0.1.0
langchain-openai>=0.0.5
langchain-anthropic>=0.1.0
langchain-community>=0.0.20
python-dotenv>=1.0.0
`;
  zip.file(`${agentName}/requirements.txt`, requirements);

  // .env template
  const envTemplate = `# Add your API keys here
# Uncomment the one you want to use

# OpenAI
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic (Claude)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# For Ollama (local models), no API key needed
# Just make sure Ollama is running: ollama serve
`;
  zip.file(`${agentName}/.env.example`, envTemplate);

  // Run script for Windows
  const runBat = `@echo off
echo ========================================
echo   ${agent.name || "AI Agent"} - AgentForge
echo ========================================
echo.

REM Check if Python is installed
python --version >nul 2>&1
if errorlevel 1 (
    echo Python is not installed. Please install Python 3.8+ from python.org
    pause
    exit /b 1
)

REM Check if virtual environment exists
if not exist "venv" (
    echo Creating virtual environment...
    python -m venv venv
)

REM Activate virtual environment
call venv\\Scripts\\activate.bat

REM Install requirements
echo Installing dependencies...
pip install -r requirements.txt -q

REM Check for .env file
if not exist ".env" (
    echo.
    echo NOTE: Please copy .env.example to .env and add your API key
    copy .env.example .env
    echo.
)

REM Run the agent
echo.
echo Starting ${agent.name || "AI Agent"}...
echo Type 'exit' or 'quit' to stop.
echo.
python agent.py

pause
`;
  zip.file(`${agentName}/run.bat`, runBat);

  // Run script for Mac/Linux
  const runSh = `#!/bin/bash

echo "========================================"
echo "  ${agent.name || "AI Agent"} - AgentForge"
echo "========================================"
echo ""

# Check if Python is installed
if ! command -v python3 &> /dev/null; then
    echo "Python 3 is not installed. Please install Python 3.8+"
    exit 1
fi

# Check if virtual environment exists
if [ ! -d "venv" ]; then
    echo "Creating virtual environment..."
    python3 -m venv venv
fi

# Activate virtual environment
source venv/bin/activate

# Install requirements
echo "Installing dependencies..."
pip install -r requirements.txt -q

# Check for .env file
if [ ! -f ".env" ]; then
    echo ""
    echo "NOTE: Please copy .env.example to .env and add your API key"
    cp .env.example .env
    echo ""
fi

# Run the agent
echo ""
echo "Starting ${agent.name || "AI Agent"}..."
echo "Type 'exit' or 'quit' to stop."
echo ""
python agent.py
`;
  zip.file(`${agentName}/run.sh`, runSh);

  // README
  const readme = generateReadme(agent);
  zip.file(`${agentName}/README.md`, readme);

  // Generate and download the zip
  const content = await zip.generateAsync({ type: "blob" });
  const url = URL.createObjectURL(content);
  const a = document.createElement("a");
  a.href = url;
  a.download = `${agentName}.zip`;
  a.click();
  URL.revokeObjectURL(url);
}

function generatePythonScript(agent: Partial<AgentConfig>): string {
  const tools = agent.tools || [];
  const modelId = agent.modelId || "gpt-4o";
  const isOllama = modelId.includes("ollama") || modelId.includes("llama");
  const isAnthropic = modelId.includes("claude");

  return `"""
${agent.name || "AI Assistant"} - Generated by AgentForge
${agent.goal ? `Goal: ${agent.goal}` : ""}

Run this agent:
  1. Copy .env.example to .env and add your API key
  2. Run: python agent.py
"""

import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

${isOllama ? `
from langchain_community.llms import Ollama

# Initialize Ollama (make sure Ollama is running: ollama serve)
llm = Ollama(
    model="${modelId.replace("ollama-", "")}",
    temperature=${agent.temperature || 0.7}
)
` : isAnthropic ? `
from langchain_anthropic import ChatAnthropic

# Initialize Anthropic
llm = ChatAnthropic(
    model="${modelId}",
    temperature=${agent.temperature || 0.7},
    max_tokens=${agent.maxTokens || 4096}
)
` : `
from langchain_openai import ChatOpenAI

# Initialize OpenAI
llm = ChatOpenAI(
    model="${modelId}",
    temperature=${agent.temperature || 0.7},
    max_tokens=${agent.maxTokens || 4096}
)
`}

from langchain.agents import AgentExecutor, create_react_agent
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.tools import Tool
from langchain_core.messages import HumanMessage, AIMessage

# System prompt
SYSTEM_PROMPT = """${agent.personality || "You are a helpful AI assistant."}

Your primary goal: ${agent.goal || "Help users with their tasks."}

Be thorough, accurate, and helpful in all your responses.
When using tools, think step by step about what you need to accomplish.
"""

# Define tools
def web_search(query: str) -> str:
    """Search the web for information."""
    return f"[Web Search] Results for: {query}"

def code_interpreter(code: str) -> str:
    """Execute Python code and return the result."""
    try:
        # Note: In production, use a proper sandboxed environment
        exec_globals = {}
        exec(code, exec_globals)
        return f"Code executed successfully. Result: {exec_globals.get('result', 'No result variable defined')}"
    except Exception as e:
        return f"Error executing code: {str(e)}"

def file_reader(filepath: str) -> str:
    """Read contents of a file."""
    try:
        with open(filepath, 'r') as f:
            return f.read()[:2000]  # Limit output
    except Exception as e:
        return f"Error reading file: {str(e)}"

def calculator(expression: str) -> str:
    """Calculate a mathematical expression."""
    try:
        result = eval(expression)
        return f"Result: {result}"
    except Exception as e:
        return f"Error: {str(e)}"

# Map tool names to functions
TOOL_MAP = {
    "web_search": Tool(name="web_search", description="Search the web for information", func=web_search),
    "code_interpreter": Tool(name="code_interpreter", description="Execute Python code", func=code_interpreter),
    "file_reader": Tool(name="file_reader", description="Read contents of a file", func=file_reader),
    "calculator": Tool(name="calculator", description="Calculate mathematical expressions", func=calculator),
    "html_generator": Tool(name="html_generator", description="Generate HTML code", func=lambda x: f"[HTML] Generated: {x}"),
    "css_generator": Tool(name="css_generator", description="Generate CSS code", func=lambda x: f"[CSS] Generated: {x}"),
    "api_caller": Tool(name="api_caller", description="Make API requests", func=lambda x: f"[API] Called: {x}"),
    "image_analysis": Tool(name="image_analysis", description="Analyze images", func=lambda x: f"[Image] Analyzed: {x}"),
}

# Get tools for this agent
tools = [TOOL_MAP.get(t, Tool(name=t, description=f"Tool: {t}", func=lambda x: f"[{t}] {x}")) for t in ${JSON.stringify(tools)}]

# Create prompt
prompt = ChatPromptTemplate.from_messages([
    ("system", SYSTEM_PROMPT),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

# Create agent
if tools:
    from langchain.agents import create_openai_functions_agent
    agent = create_openai_functions_agent(llm, tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)
else:
    agent_executor = None

def chat(message: str, chat_history: list = None) -> str:
    """Send a message to the agent and get a response."""
    if chat_history is None:
        chat_history = []
    
    if agent_executor:
        response = agent_executor.invoke({
            "input": message,
            "chat_history": chat_history
        })
        return response["output"]
    else:
        # Simple chat without tools
        messages = [("system", SYSTEM_PROMPT)]
        for h in chat_history:
            messages.append(h)
        messages.append(("human", message))
        
        from langchain_core.prompts import ChatPromptTemplate
        simple_prompt = ChatPromptTemplate.from_messages(messages)
        chain = simple_prompt | llm
        response = chain.invoke({})
        return response.content if hasattr(response, 'content') else str(response)

def main():
    """Main chat loop."""
    print(f"\\nðŸ¤– {agent.name or "AI Assistant"} is ready!")
    print("=" * 50)
    print(f"Goal: ${agent.goal || "Help you with your tasks"}")
    print("=" * 50)
    print("\\nType your message and press Enter. Type 'exit' to quit.\\n")
    
    chat_history = []
    
    while True:
        try:
            user_input = input("You: ").strip()
            
            if not user_input:
                continue
                
            if user_input.lower() in ["exit", "quit", "bye"]:
                print("\\nGoodbye! ðŸ‘‹")
                break
            
            response = chat(user_input, chat_history)
            print(f"\\nðŸ¤– Agent: {response}\\n")
            
            # Update chat history
            chat_history.append(("human", user_input))
            chat_history.append(("ai", response))
            
        except KeyboardInterrupt:
            print("\\n\\nGoodbye! ðŸ‘‹")
            break
        except Exception as e:
            print(f"\\nError: {str(e)}\\n")

if __name__ == "__main__":
    main()
`;
}

function generateReadme(agent: Partial<AgentConfig>): string {
  return `# ${agent.name || "AI Agent"}

> Generated by [AgentForge](https://agentforge.dev)

${agent.goal ? `**Goal:** ${agent.goal}` : ""}

${agent.personality ? `**Personality:** ${agent.personality}` : ""}

## Quick Start

### Option 1: One-Click Run (Easiest)

**Windows:**
\`\`\`
Double-click run.bat
\`\`\`

**Mac/Linux:**
\`\`\`bash
chmod +x run.sh
./run.sh
\`\`\`

### Option 2: Manual Setup

1. **Create a virtual environment:**
   \`\`\`bash
   python -m venv venv
   source venv/bin/activate  # Mac/Linux
   # or
   venv\\Scripts\\activate  # Windows
   \`\`\`

2. **Install dependencies:**
   \`\`\`bash
   pip install -r requirements.txt
   \`\`\`

3. **Set up your API key:**
   \`\`\`bash
   cp .env.example .env
   # Edit .env and add your API key
   \`\`\`

4. **Run the agent:**
   \`\`\`bash
   python agent.py
   \`\`\`

## Using Ollama (Free Local AI)

Want to run this agent completely free and offline? Use Ollama!

1. Install Ollama: https://ollama.ai
2. Pull a model: \`ollama pull llama3.1\`
3. Start Ollama: \`ollama serve\`
4. Update the model in \`agent.py\` to use Ollama

## Configuration

Edit \`config.json\` to customize:
- Agent name and goal
- Available tools
- Model settings (temperature, max tokens)

## Tools Available

${(agent.tools || []).map(t => `- **${t.replace(/_/g, " ")}**`).join("\n")}

## Need Help?

- Visit [AgentForge](https://agentforge.dev) to build more agents
- Check the [LangChain docs](https://python.langchain.com/) for advanced customization

---
Built with AgentForge - Zero platform fees, powered by your models.
`;
}
