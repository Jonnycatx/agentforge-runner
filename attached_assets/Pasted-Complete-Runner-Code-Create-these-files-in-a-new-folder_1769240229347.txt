Complete Runner Code
Create these files in a new folder called runner/ in your project:
1. runner/package.json
{  "name": "agentforge-runner",  "version": "1.0.0",  "description": "Native desktop app for running AgentForge agents",  "scripts": {    "dev": "vite",    "build": "vite build",    "tauri": "tauri",    "tauri:dev": "tauri dev",    "tauri:build": "tauri build"  },  "dependencies": {    "react": "^18.2.0",    "react-dom": "^18.2.0",    "lucide-react": "^0.294.0",    "clsx": "^2.0.0"  },  "devDependencies": {    "@tauri-apps/cli": "^2.0.0",    "@tauri-apps/api": "^2.0.0",    "@types/react": "^18.2.0",    "@types/react-dom": "^18.2.0",    "@vitejs/plugin-react": "^4.2.0",    "autoprefixer": "^10.4.16",    "postcss": "^8.4.32",    "tailwindcss": "^3.4.0",    "typescript": "^5.3.0",    "vite": "^5.0.0"  }}
2. runner/vite.config.ts
import { defineConfig } from 'vite';import react from '@vitejs/plugin-react';export default defineConfig({  plugins: [react()],  clearScreen: false,  server: {    port: 1420,    strictPort: true,  },  envPrefix: ['VITE_', 'TAURI_'],  build: {    target: ['es2021', 'chrome100', 'safari13'],    minify: !process.env.TAURI_DEBUG ? 'esbuild' : false,    sourcemap: !!process.env.TAURI_DEBUG,  },});
3. runner/tailwind.config.js
/** @type {import('tailwindcss').Config} */export default {  content: ['./index.html', './src/**/*.{js,ts,jsx,tsx}'],  theme: {    extend: {},  },  plugins: [],};
4. runner/postcss.config.js
export default {  plugins: {    tailwindcss: {},    autoprefixer: {},  },};
5. runner/tsconfig.json
{  "compilerOptions": {    "target": "ES2020",    "useDefineForClassFields": true,    "lib": ["ES2020", "DOM", "DOM.Iterable"],    "module": "ESNext",    "skipLibCheck": true,    "moduleResolution": "bundler",    "allowImportingTsExtensions": true,    "resolveJsonModule": true,    "isolatedModules": true,    "noEmit": true,    "jsx": "react-jsx",    "strict": true,    "noUnusedLocals": true,    "noUnusedParameters": true,    "noFallthroughCasesInSwitch": true  },  "include": ["src"],  "references": [{ "path": "./tsconfig.node.json" }]}
6. runner/tsconfig.node.json
{  "compilerOptions": {    "composite": true,    "skipLibCheck": true,    "module": "ESNext",    "moduleResolution": "bundler",    "allowSyntheticDefaultImports": true  },  "include": ["vite.config.ts"]}
7. runner/index.html
<!DOCTYPE html><html lang="en">  <head>    <meta charset="UTF-8" />    <meta name="viewport" content="width=device-width, initial-scale=1.0" />    <title>AgentForge Runner</title>    <style>      html, body, #root {        height: 100%;        margin: 0;        padding: 0;      }    </style>  </head>  <body>    <div id="root"></div>    <script type="module" src="/src/main.tsx"></script>  </body></html>
8. runner/src/main.tsx
import React from 'react';import ReactDOM from 'react-dom/client';import App from './App';import './index.css';ReactDOM.createRoot(document.getElementById('root')!).render(  <React.StrictMode>    <App />  </React.StrictMode>);
9. runner/src/index.css
@tailwind base;@tailwind components;@tailwind utilities;* {  user-select: none;  -webkit-user-select: none;}input, textarea {  user-select: text;  -webkit-user-select: text;}::-webkit-scrollbar {  width: 8px;}::-webkit-scrollbar-track {  background: #1f2937;}::-webkit-scrollbar-thumb {  background: #4b5563;  border-radius: 4px;}::-webkit-scrollbar-thumb:hover {  background: #6b7280;}
10. runner/src/App.tsx
import { useState, useEffect, useRef } from 'react';import { Send, Settings, Bot, User, Loader2, AlertCircle, CheckCircle2 } from 'lucide-react';import { clsx } from 'clsx';interface Message {  id: string;  role: 'user' | 'assistant' | 'system';  content: string;  timestamp: Date;}interface AgentConfig {  name: string;  goal: string;  personality: string;  avatar?: string;  provider: string;  model: string;  apiKey?: string;  temperature: number;  tools: string[];}const DEFAULT_CONFIG: AgentConfig = {  name: 'AI Assistant',  goal: 'Help users with various tasks',  personality: 'You are a helpful, friendly AI assistant.',  provider: 'ollama',  model: 'llama3.2',  temperature: 0.7,  tools: [],};// API endpoint - Python sidecar runs on this portconst API_URL = 'http://127.0.0.1:8765';export default function App() {  const [messages, setMessages] = useState<Message[]>([]);  const [input, setInput] = useState('');  const [isLoading, setIsLoading] = useState(false);  const [config, setConfig] = useState<AgentConfig>(DEFAULT_CONFIG);  const [showSettings, setShowSettings] = useState(false);  const [connectionStatus, setConnectionStatus] = useState<'checking' | 'connected' | 'error'>('checking');  const [error, setError] = useState<string | null>(null);  const messagesEndRef = useRef<HTMLDivElement>(null);  // Check backend connection on mount  useEffect(() => {    checkConnection();    loadConfigFromFile();  }, []);  // Auto-scroll to bottom  useEffect(() => {    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });  }, [messages]);  const checkConnection = async () => {    setConnectionStatus('checking');    try {      const res = await fetch(`${API_URL}/health`, {         method: 'GET',        signal: AbortSignal.timeout(5000),      });      if (res.ok) {        setConnectionStatus('connected');        setError(null);      } else {        throw new Error('Backend not responding');      }    } catch (e) {      setConnectionStatus('error');      setError('Cannot connect to agent backend. Make sure the Python server is running.');    }  };  const loadConfigFromFile = async () => {    try {      // Try to load config from command line args (passed by Tauri)      const res = await fetch(`${API_URL}/config`);      if (res.ok) {        const data = await res.json();        if (data.config) {          setConfig({ ...DEFAULT_CONFIG, ...data.config });          // Add welcome message          setMessages([{            id: '1',            role: 'assistant',            content: `Hi! I'm ${data.config.name || 'your AI assistant'}. ${data.config.goal ? `My goal is to ${data.config.goal.toLowerCase()}.` : ''} How can I help you today?`,            timestamp: new Date(),          }]);        }      }    } catch (e) {      console.log('No config file loaded, using defaults');    }  };  const sendMessage = async () => {    if (!input.trim() || isLoading) return;    const userMessage: Message = {      id: Date.now().toString(),      role: 'user',      content: input.trim(),      timestamp: new Date(),    };    setMessages(prev => [...prev, userMessage]);    setInput('');    setIsLoading(true);    setError(null);    try {      const res = await fetch(`${API_URL}/chat`, {        method: 'POST',        headers: { 'Content-Type': 'application/json' },        body: JSON.stringify({          message: userMessage.content,          config: config,          history: messages.slice(-10).map(m => ({ role: m.role, content: m.content })),        }),        signal: AbortSignal.timeout(60000),      });      if (!res.ok) {        const errorData = await res.json().catch(() => ({}));        throw new Error(errorData.error || `Request failed: ${res.status}`);      }      const data = await res.json();            const assistantMessage: Message = {        id: (Date.now() + 1).toString(),        role: 'assistant',        content: data.response || 'I apologize, but I could not generate a response.',        timestamp: new Date(),      };      setMessages(prev => [...prev, assistantMessage]);    } catch (e) {      const errorMsg = e instanceof Error ? e.message : 'Failed to get response';      setError(errorMsg);            setMessages(prev => [...prev, {        id: (Date.now() + 1).toString(),        role: 'assistant',        content: `⚠️ Error: ${errorMsg}`,        timestamp: new Date(),      }]);    } finally {      setIsLoading(false);    }  };  const handleKeyDown = (e: React.KeyboardEvent) => {    if (e.key === 'Enter' && !e.shiftKey) {      e.preventDefault();      sendMessage();    }  };  return (    <div className="flex flex-col h-screen bg-gray-900 text-white">      {/* Header */}      <header className="flex items-center justify-between px-4 py-3 bg-gray-800 border-b border-gray-700">        <div className="flex items-center gap-3">          {config.avatar ? (            <img src={config.avatar} alt="Avatar" className="w-10 h-10 rounded-full object-cover" />          ) : (            <div className="w-10 h-10 rounded-full bg-gradient-to-br from-blue-500 to-purple-600 flex items-center justify-center">              <Bot className="w-6 h-6" />            </div>          )}          <div>            <h1 className="font-semibold">{config.name}</h1>            <p className="text-xs text-gray-400">{config.provider} / {config.model}</p>          </div>        </div>                <div className="flex items-center gap-2">          {/* Connection Status */}          <div className={clsx(            'flex items-center gap-1.5 px-2 py-1 rounded-full text-xs',            connectionStatus === 'connected' && 'bg-green-900/50 text-green-400',            connectionStatus === 'checking' && 'bg-yellow-900/50 text-yellow-400',            connectionStatus === 'error' && 'bg-red-900/50 text-red-400',          )}>            {connectionStatus === 'connected' && <CheckCircle2 className="w-3 h-3" />}            {connectionStatus === 'checking' && <Loader2 className="w-3 h-3 animate-spin" />}            {connectionStatus === 'error' && <AlertCircle className="w-3 h-3" />}            <span className="capitalize">{connectionStatus}</span>          </div>                    <button            onClick={() => setShowSettings(!showSettings)}            className="p-2 hover:bg-gray-700 rounded-lg transition-colors"          >            <Settings className="w-5 h-5" />          </button>        </div>      </header>      {/* Settings Panel */}      {showSettings && (        <div className="px-4 py-3 bg-gray-800 border-b border-gray-700 space-y-3">          <div className="grid grid-cols-2 gap-3">            <div>              <label className="text-xs text-gray-400">Provider</label>              <select                value={config.provider}                onChange={e => setConfig(c => ({ ...c, provider: e.target.value }))}                className="w-full mt-1 px-3 py-2 bg-gray-700 rounded-lg text-sm outline-none"              >                <option value="ollama">Ollama (Local)</option>                <option value="openai">OpenAI</option>                <option value="anthropic">Anthropic</option>                <option value="xai">xAI (Grok)</option>                <option value="groq">Groq</option>                <option value="google">Google AI</option>              </select>            </div>            <div>              <label className="text-xs text-gray-400">Model</label>              <input                type="text"                value={config.model}                onChange={e => setConfig(c => ({ ...c, model: e.target.value }))}                className="w-full mt-1 px-3 py-2 bg-gray-700 rounded-lg text-sm outline-none"                placeholder="llama3.2, gpt-4o, etc."              />            </div>          </div>          {config.provider !== 'ollama' && (            <div>              <label className="text-xs text-gray-400">API Key</label>              <input                type="password"                value={config.apiKey || ''}                onChange={e => setConfig(c => ({ ...c, apiKey: e.target.value }))}                className="w-full mt-1 px-3 py-2 bg-gray-700 rounded-lg text-sm outline-none"                placeholder="Enter your API key"              />            </div>          )}          <button            onClick={checkConnection}            className="px-4 py-2 bg-blue-600 hover:bg-blue-700 rounded-lg text-sm transition-colors"          >            Test Connection          </button>        </div>      )}      {/* Error Banner */}      {error && (        <div className="px-4 py-2 bg-red-900/50 border-b border-red-800 text-red-200 text-sm flex items-center gap-2">          <AlertCircle className="w-4 h-4" />          {error}        </div>      )}      {/* Messages */}      <div className="flex-1 overflow-y-auto p-4 space-y-4">        {messages.length === 0 && (          <div className="flex flex-col items-center justify-center h-full text-gray-500">            <Bot className="w-16 h-16 mb-4 opacity-50" />            <p>Start a conversation with {config.name}</p>          </div>        )}                {messages.map(msg => (          <div            key={msg.id}            className={clsx(              'flex gap-3',              msg.role === 'user' && 'flex-row-reverse'            )}          >            <div className={clsx(              'w-8 h-8 rounded-full flex items-center justify-center shrink-0',              msg.role === 'user' ? 'bg-blue-600' : 'bg-gray-700'            )}>              {msg.role === 'user' ? <User className="w-4 h-4" /> : <Bot className="w-4 h-4" />}            </div>            <div className={clsx(              'max-w-[75%] px-4 py-2 rounded-2xl',              msg.role === 'user'                 ? 'bg-blue-600 rounded-br-md'                 : 'bg-gray-700 rounded-bl-md'            )}>              <p className="whitespace-pre-wrap">{msg.content}</p>              <p className="text-xs opacity-50 mt-1">                {msg.timestamp.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })}              </p>            </div>          </div>        ))}                {isLoading && (          <div className="flex gap-3">            <div className="w-8 h-8 rounded-full bg-gray-700 flex items-center justify-center">              <Bot className="w-4 h-4" />            </div>            <div className="bg-gray-700 px-4 py-3 rounded-2xl rounded-bl-md">              <Loader2 className="w-5 h-5 animate-spin" />            </div>          </div>        )}                <div ref={messagesEndRef} />      </div>      {/* Input */}      <div className="p-4 bg-gray-800 border-t border-gray-700">        <div className="flex gap-2">          <textarea            value={input}            onChange={e => setInput(e.target.value)}            onKeyDown={handleKeyDown}            placeholder="Type a message..."            rows={1}            className="flex-1 px-4 py-3 bg-gray-700 rounded-xl outline-none resize-none text-sm"            style={{ maxHeight: '120px' }}          />          <button            onClick={sendMessage}            disabled={!input.trim() || isLoading || connectionStatus !== 'connected'}            className={clsx(              'px-4 rounded-xl transition-colors flex items-center justify-center',              input.trim() && !isLoading && connectionStatus === 'connected'                ? 'bg-blue-600 hover:bg-blue-700'                : 'bg-gray-700 opacity-50 cursor-not-allowed'            )}          >            <Send className="w-5 h-5" />          </button>        </div>      </div>    </div>  );}
11. runner/src-tauri/Cargo.toml
[package]name = "agentforge-runner"version = "1.0.0"description = "Native desktop app for AgentForge agents"authors = ["AgentForge"]edition = "2021"[build-dependencies]tauri-build = { version = "2", features = [] }[dependencies]tauri = { version = "2", features = ["shell-open"] }tauri-plugin-shell = "2"serde = { version = "1", features = ["derive"] }serde_json = "1"[features]default = ["custom-protocol"]custom-protocol = ["tauri/custom-protocol"]
12. runner/src-tauri/tauri.conf.json
{  "$schema": "https://schema.tauri.app/config/2",  "productName": "AgentForge Runner",  "version": "1.0.0",  "identifier": "com.agentforge.runner",  "build": {    "beforeBuildCommand": "npm run build",    "beforeDevCommand": "npm run dev",    "frontendDist": "../dist",    "devUrl": "http://localhost:1420"  },  "app": {    "windows": [      {        "title": "AgentForge Runner",        "width": 480,        "height": 720,        "minWidth": 400,        "minHeight": 500,        "resizable": true,        "center": true,        "decorations": true,        "transparent": false      }    ],    "security": {      "csp": null    }  },  "bundle": {    "active": true,    "targets": "all",    "icon": [      "icons/32x32.png",      "icons/128x128.png",      "icons/128x128@2x.png",      "icons/icon.icns",      "icons/icon.ico"    ],    "macOS": {      "entitlements": null,      "exceptionDomain": "",      "frameworks": [],      "providerShortName": null,      "signingIdentity": null,      "minimumSystemVersion": "10.13"    },    "windows": {      "certificateThumbprint": null,      "digestAlgorithm": "sha256",      "timestampUrl": ""    }  }}
13. runner/src-tauri/src/main.rs
#![cfg_attr(not(debug_assertions), windows_subsystem = "windows")]use std::process::{Command, Stdio};use std::path::PathBuf;use tauri::Manager;fn get_python_path() -> PathBuf {    let resource_path = std::env::current_exe()        .expect("Failed to get executable path")        .parent()        .expect("Failed to get parent directory")        .join("resources")        .join("python");        resource_path.join("agent_server.py")}fn spawn_python_backend() {    let python_script = get_python_path();        println!("Starting Python backend from: {:?}", python_script);        // Try python3 first (macOS/Linux), then python (Windows)    let python_cmd = if cfg!(target_os = "windows") {        "python"    } else {        "python3"    };        match Command::new(python_cmd)        .arg(&python_script)        .stdout(Stdio::piped())        .stderr(Stdio::piped())        .spawn()    {        Ok(child) => {            println!("Python backend started with PID: {}", child.id());        }        Err(e) => {            eprintln!("Failed to start Python backend: {}", e);            eprintln!("Make sure Python 3 is installed and in your PATH");        }    }}fn main() {    // Start Python backend    spawn_python_backend();        // Give Python a moment to start    std::thread::sleep(std::time::Duration::from_millis(1000));        tauri::Builder::default()        .plugin(tauri_plugin_shell::init())        .setup(|app| {            let window = app.get_webview_window("main").unwrap();                        // Focus window on startup            window.set_focus().unwrap();                        Ok(())        })        .run(tauri::generate_context!())        .expect("error while running tauri application");}
14. runner/src-tauri/build.rs
fn main() {    tauri_build::build()}
15. runner/src-tauri/resources/python/agent_server.py
#!/usr/bin/env python3"""AgentForge Runner - Python Backend ServerHandles AI inference for the desktop app"""from http.server import HTTPServer, BaseHTTPRequestHandlerimport jsonimport urllib.requestimport urllib.errorimport sslimport osimport sys# ConfigurationHOST = '127.0.0.1'PORT = 8765# Current agent config (loaded from .agentforge file or set via API)current_config = {    "name": "AI Assistant",    "goal": "Help users with various tasks",    "personality": "You are a helpful AI assistant.",    "provider": "ollama",    "model": "llama3.2",    "apiKey": "",    "temperature": 0.7,}class AgentHandler(BaseHTTPRequestHandler):    def _send_response(self, status_code, data):        self.send_response(status_code)        self.send_header('Content-Type', 'application/json')        self.send_header('Access-Control-Allow-Origin', '*')        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')        self.send_header('Access-Control-Allow-Headers', 'Content-Type')        self.end_headers()        self.wfile.write(json.dumps(data).encode())    def do_OPTIONS(self):        self.send_response(200)        self.send_header('Access-Control-Allow-Origin', '*')        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')        self.send_header('Access-Control-Allow-Headers', 'Content-Type')        self.end_headers()    def do_GET(self):        if self.path == '/health':            self._send_response(200, {"status": "ok", "message": "Agent server running"})        elif self.path == '/config':            self._send_response(200, {"config": current_config})        else:            self._send_response(404, {"error": "Not found"})    def do_POST(self):        content_length = int(self.headers.get('Content-Length', 0))        body = self.rfile.read(content_length)                try:            data = json.loads(body) if body else {}        except json.JSONDecodeError:            self._send_response(400, {"error": "Invalid JSON"})            return        if self.path == '/chat':            self._handle_chat(data)        elif self.path == '/config':            self._handle_config_update(data)        elif self.path == '/load-file':            self._handle_load_file(data)        else:            self._send_response(404, {"error": "Not found"})    def _handle_config_update(self, data):        global current_config        if 'config' in data:            current_config.update(data['config'])        self._send_response(200, {"status": "ok", "config": current_config})    def _handle_load_file(self, data):        global current_config        file_path = data.get('path', '')                if not file_path or not os.path.exists(file_path):            self._send_response(400, {"error": f"File not found: {file_path}"})            return                try:            with open(file_path, 'r') as f:                file_config = json.load(f)                current_config.update(file_config)                self._send_response(200, {"status": "ok", "config": current_config})        except Exception as e:            self._send_response(500, {"error": str(e)})    def _handle_chat(self, data):        message = data.get('message', '')        config = data.get('config', current_config)        history = data.get('history', [])                if not message:            self._send_response(400, {"error": "Message is required"})            return        provider = config.get('provider', 'ollama')        model = config.get('model', 'llama3.2')        api_key = config.get('apiKey', '')        personality = config.get('personality', 'You are a helpful assistant.')        temperature = config.get('temperature', 0.7)        try:            if provider == 'ollama':                response = self._call_ollama(model, personality, message, history, temperature)            elif provider == 'openai':                response = self._call_openai(model, api_key, personality, message, history, temperature)            elif provider == 'anthropic':                response = self._call_anthropic(model, api_key, personality, message, history, temperature)            elif provider == 'xai':                response = self._call_xai(model, api_key, personality, message, history, temperature)            elif provider == 'groq':                response = self._call_groq(model, api_key, personality, message, history, temperature)            elif provider == 'google':                response = self._call_google(model, api_key, personality, message, history, temperature)            else:                response = f"Unknown provider: {provider}"                        self._send_response(200, {"response": response})        except Exception as e:            self._send_response(500, {"error": str(e)})    def _make_request(self, url, headers, body):        """Make HTTP request with proper error handling"""        req = urllib.request.Request(            url,            data=json.dumps(body).encode('utf-8'),            headers=headers,            method='POST'        )                # Create SSL context that doesn't verify (for development)        ctx = ssl.create_default_context()        ctx.check_hostname = False        ctx.verify_mode = ssl.CERT_NONE                try:            with urllib.request.urlopen(req, timeout=60, context=ctx) as response:                return json.loads(response.read().decode('utf-8'))        except urllib.error.HTTPError as e:            error_body = e.read().decode('utf-8')            raise Exception(f"API Error ({e.code}): {error_body}")        except urllib.error.URLError as e:            raise Exception(f"Connection Error: {e.reason}")    def _call_ollama(self, model, personality, message, history, temperature):        """Call local Ollama server"""        messages = [{"role": "system", "content": personality}]        messages.extend(history)        messages.append({"role": "user", "content": message})                body = {            "model": model,            "messages": messages,            "stream": False,            "options": {"temperature": temperature}        }                try:            result = self._make_request(                "http://localhost:11434/api/chat",                {"Content-Type": "application/json"},                body            )            return result.get("message", {}).get("content", "No response from Ollama")        except Exception as e:            if "Connection" in str(e):                return "⚠️ Cannot connect to Ollama. Make sure it's running with 'ollama serve'"            raise    def _call_openai(self, model, api_key, personality, message, history, temperature):        """Call OpenAI API"""        if not api_key:            return "⚠️ OpenAI API key is required. Add it in Settings."                messages = [{"role": "system", "content": personality}]        messages.extend(history)        messages.append({"role": "user", "content": message})                result = self._make_request(            "https://api.openai.com/v1/chat/completions",            {                "Content-Type": "application/json",                "Authorization": f"Bearer {api_key}"            },            {                "model": model,                "messages": messages,                "temperature": temperature,            }        )        return result["choices"][0]["message"]["content"]    def _call_anthropic(self, model, api_key, personality, message, history, temperature):        """Call Anthropic API"""        if not api_key:            return "⚠️ Anthropic API key is required. Add it in Settings."                messages = []        messages.extend(history)        messages.append({"role": "user", "content": message})                result = self._make_request(            "https://api.anthropic.com/v1/messages",            {                "Content-Type": "application/json",                "x-api-key": api_key,                "anthropic-version": "2023-06-01"            },            {                "model": model,                "max_tokens": 4096,                "system": personality,                "messages": messages,            }        )        return result["content"][0]["text"]    def _call_xai(self, model, api_key, personality, message, history, temperature):        """Call xAI (Grok) API"""        if not api_key:            return "⚠️ xAI API key is required. Add it in Settings."                messages = [{"role": "system", "content": personality}]        messages.extend(history)        messages.append({"role": "user", "content": message})                result = self._make_request(            "https://api.x.ai/v1/chat/completions",            {                "Content-Type": "application/json",                "Authorization": f"Bearer {api_key}"            },            {                "model": model,                "messages": messages,                "temperature": temperature,            }        )        return result["choices"][0]["message"]["content"]    def _call_groq(self, model, api_key, personality, message, history, temperature):        """Call Groq API"""        if not api_key:            return "⚠️ Groq API key is required. Add it in Settings."                messages = [{"role": "system", "content": personality}]        messages.extend(history)        messages.append({"role": "user", "content": message})                result = self._make_request(            "https://api.groq.com/openai/v1/chat/completions",            {                "Content-Type": "application/json",                "Authorization": f"Bearer {api_key}"            },            {                "model": model,                "messages": messages,                "temperature": temperature,            }        )        return result["choices"][0]["message"]["content"]    def _call_google(self, model, api_key, personality, message, history, temperature):        """Call Google AI API"""        if not api_key:            return "⚠️ Google AI API key is required. Add it in Settings."                # Google uses a different format        contents = []        for msg in history:            role = "user" if msg["role"] == "user" else "model"            contents.append({"role": role, "parts": [{"text": msg["content"]}]})        contents.append({"role": "user", "parts": [{"text": message}]})                result = self._make_request(            f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}",            {"Content-Type": "application/json"},            {                "contents": contents,                "systemInstruction": {"parts": [{"text": personality}]},                "generationConfig": {"temperature": temperature}            }        )        return result["candidates"][0]["content"]["parts"][0]["text"]    def log_message(self, format, *args):        # Suppress default logging        passdef main():    print(f"Starting AgentForge Runner backend on {HOST}:{PORT}")    server = HTTPServer((HOST, PORT), AgentHandler)        try:        server.serve_forever()    except KeyboardInterrupt:        print("\nShutting down server...")        server.shutdown()if __name__ == "__main__":    main()
16. runner/.github/workflows/build.yml (Auto-builds Mac/Windows)
name: Build and Releaseon:  push:    tags:      - 'v*'  workflow_dispatch:jobs:  build:    strategy:      fail-fast: false      matrix:        include:          - platform: macos-latest            target: universal-apple-darwin            bundles: dmg          - platform: windows-latest            target: x86_64-pc-windows-msvc            bundles: msi,nsis    runs-on: ${{ matrix.platform }}        steps:      - uses: actions/checkout@v4            - name: Setup Node        uses: actions/setup-node@v4        with:          node-version: 20                - name: Setup Rust        uses: dtolnay/rust-action@stable              - name: Install dependencies (macOS)        if: matrix.platform == 'macos-latest'        run: |          rustup target add aarch64-apple-darwin x86_64-apple-darwin                - name: Install frontend dependencies        run: npm install        working-directory: runner              - name: Build Tauri app        uses: tauri-apps/tauri-action@v0        env:          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}        with:          projectPath: runner          tagName: v__VERSION__          releaseName: 'AgentForge Runner v__VERSION__'          releaseBody: 'Download the installer for your platform below.'          releaseDraft: false          prerelease: false          args: --target ${{ matrix.target }} --bundles ${{ matrix.bundles }}
17. runner/README.md
# AgentForge RunnerNative desktop app for running AgentForge agents.## Development### Prerequisites- Node.js 18+- Rust (install from rustup.rs)- Python 3.8+### Setupcd runnernpm install
Run in development
# Start Python backendpython3 src-tauri/resources/python/agent_server.py &# Start Tauri devnpm run tauri dev
Build for production
npm run tauri build
Outputs will be in src-tauri/target/release/bundle/
Architecture
┌─────────────────────────────────────┐│         Tauri Window (Rust)         ││  ┌─────────────────────────────┐    ││  │    React Frontend (Chat UI) │    ││  │    - Avatar display         │    ││  │    - Message history        │    ││  │    - Input field            │    ││  └─────────────────────────────┘    ││              │ HTTP                 ││              ▼                      ││  ┌─────────────────────────────┐    ││  │  Python Backend (Hidden)    │    ││  │  - localhost:8765           │    ││  │  - Ollama / Cloud APIs      │    ││  └─────────────────────────────┘    │└─────────────────────────────────────┘
Supported Providers
Ollama (local, free)
OpenAI
Anthropic
xAI (Grok)
Groq
Google AI
---## How to Use This1. **Create the `runner/` folder** in your Replit project2. **Copy each file** into the correct location3. **Push to GitHub** - the workflow will auto-build Mac/Windows installers4. **Update your download link** to point to the GitHub releases### Quick Setup Commands for Replit:mkdir -p runner/src runner/src-tauri/src runner/src-tauri/resources/python runner/.github/workflows
Then paste each file's content into the appropriate location.
The GitHub Actions workflow will automatically build .dmg (Mac) and .msi (Windows) installers whenever you create a new release tag like v1.0.0.